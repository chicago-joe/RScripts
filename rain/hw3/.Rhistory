alldata <- cbind(rf.raw, returns)["20141001/20181001"]
# create excess returns
equity.names.xs <- paste(equity.names, ".xs", sep="")
alldata.xs<-c()
# now in a for loop subtract off a daily risk-free rate, for example:
for (i in 1:length(equity.names)+1) {
xs.temp <- alldata[,i] - alldata$T3M/250
alldata.xs <- cbind(alldata.xs, xs.temp)
}
colnames(alldata.xs) <- equity.names.xs
alldata.xs<-na.omit(alldata.xs)["20141001/20181001"]
alldata.chen <- cbind( alldata.xs,chen)
alldata.chen <- na.locf(alldata.chen)["20141001/20181001"]
#model.temp <-lm(alldata.chen[,1]~alldata.chen[,12]+alldata.chen[,13]+alldata.chen[,14]+alldata.chen[,15]+alldata.chen[,11])
#model.temp<-summary(model.temp)
allmodel.coefficients<-c()
allmodel.coefficients.name<-c()
for (i in 1:length(equity.names)){
model.temp <-lm(alldata.chen[,i]~alldata.chen[,12]+alldata.chen[,13]+alldata.chen[,14]+alldata.chen[,15]+alldata.chen[,11])
model.temp<-summary(model.temp)
allmodel.coefficients<-cbind(allmodel.coefficients,model.temp$coefficients[,c(1,4)])
allmodel.coefficients.name<-cbind(allmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
allmodel.coefficients<-allmodel.coefficients
colnames(allmodel.coefficients)<-allmodel.coefficients.name
print(allmodel.coefficients)
# Now do GARCH-in-mean models
gim.spec <- ugarchspec(variance.model=list(model="sGARCH", archm=TRUE, archpow=2),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE))
garch.in.mean.spx <- ugarchfit(data=alldata.xs$SPX.xs, spec=gim.spec)
x<-show(garch.in.mean.spx)
x@fit$coef
sum(x@fit$log.likelihoods)
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$coef)
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
## Download Fama-French data
french.base <- "http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp"
factor.file <- "F-F_Research_Data_Factors_daily_CSV.zip"
french.url <- paste(french.base, factor.file, sep="/")
temp.file <- tempfile()
download.file(french.url, destfile=temp.file)
ff.tmp <- read.csv(unz(temp.file, "F-F_Research_Data_Factors_daily.CSV"),
header = TRUE, skip = 3)
unlink(temp.file)
# remove obnoxious last line, scale percentages, create xts object
ff.tmp <- ff.tmp[-length(ff.tmp[,1]),]
ff.data <- as.xts(ff.tmp[,c("SMB","HML")],
order.by=as.POSIXct(ff.tmp[[1]], format="%Y%m%d"))
ff.data <- ff.data["20141001/20181001"]
alldata.ff <- cbind( alldata.xs,ff.data)
alldata.ff <- na.locf(alldata.ff)["20141001/20181001"]
alldata.ff <- na.omit(alldata.ff)["20141001/20181001"]
ffmodel.coefficients<-c()
ffmodel.coefficients.name<-c()
for (i in 3:length(equity.names)){
model.temp <-lm(alldata.ff[,i]~alldata.ff[,1]+alldata.ff[,11]+alldata.ff[,12])
model.temp<-summary(model.temp)
ffmodel.coefficients<-cbind(ffmodel.coefficients,model.temp$coefficients[,c(1,4)])
ffmodel.coefficients.name<-cbind(ffmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
ffmodel.coefficients<-ffmodel.coefficients
colnames(ffmodel.coefficients)<-ffmodel.coefficients.name
print(ffmodel.coefficients)
print(allmodel.coefficients)
View(chen)
## Dale W.R. Rosenthal, 2018
## You are free to distribute and use this code so long as you attribute
## it to me or cite the text.
## The legal disclaimer in _A Quantitative Primer on Investments with R_
## applies to this code.  Use or distribution without these comment lines
## is forbidden.
library(xts)
library(Quandl)
library(quantmod)
Quandl.api_key('iVyBuKymy_j_R7Xxze9t')
# Get risk-free rate
rf.raw <- Quandl("FRED/DGS3MO", type="xts")/100
colnames(rf.raw) <- c("T3M")
# Get S&P 500, Russell 2000, and stock returns
adj.close <- 6  # 6th field is adjusted close
equity.tickers <- c("^GSPC","^RUT","BA","GD","HON","LMT","NOC","QCOM","RTN","UTX")
prices <- getSymbols(equity.tickers[1], source="yahoo", auto.assign=FALSE,
return.class="xts")[,adj.close]
for (i in 2:length(equity.tickers)) {
prices.tmp <- getSymbols(equity.tickers[i], source="yahoo",
auto.assign=FALSE, return.class="xts")[,adj.close]
prices <- cbind(prices, prices.tmp)
}
equity.names <- c("SPX","RUT","BA","GD","HON","LMT","NOC","QCOM","RTN","UTX")
colnames(prices) <- equity.names
returns <- diff(log(prices))
# Now we join all of the datasets together and trim to recent
alldata <- cbind(rf.raw, returns)["20141001/20181001"]
# create excess returns
equity.names.xs <- paste(equity.names, ".xs", sep="")
alldata.xs<-c()
# now in a for loop subtract off a daily risk-free rate, for example:
for (i in 1:length(equity.names)+1) {
xs.temp <- alldata[,i] - alldata$T3M/250
alldata.xs <- cbind(alldata.xs, xs.temp)
}
colnames(alldata.xs) <- equity.names.xs
# If your ticker were DAL and you wanted to model returns
# (not excess returns) using ESTOX and SMI, you would do like so:
model.temp <- lm(SPX.xs ~  + RUT.xs, data=alldata.xs)
model.temp<-summary(model.temp)
allmodel.coefficients<-c()
allmodel.coefficients.name<-c()
for (i in 3:length(equity.names)){
model.temp <-lm(alldata.xs[,i]~alldata.xs[,1]+alldata.xs[,2])
model.temp<-summary(model.temp)
allmodel.coefficients<-cbind(allmodel.coefficients,model.temp$coefficients[,c(1,2,4)])
allmodel.coefficients.name<-cbind(allmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
allmodel.coefficients<-allmodel.coefficients
colnames(allmodel.coefficients)<-allmodel.coefficients.name
allmodel.coefficients
# NOTE that this is not the model you are supposed to do
allmodel.coefficients<-c()
allmodel.coefficients.name<-c()
for (i in 1:length(equity.names)){
model.temp <-lm(alldata.chen[,i]~alldata.chen[,12]+alldata.chen[,13]+alldata.chen[,14]+alldata.chen[,15]+alldata.chen[,11])
model.temp<-summary(model.temp)
allmodel.coefficients<-cbind(allmodel.coefficients,model.temp$coefficients[,c(1,2,3,4)])
allmodel.coefficients.name<-cbind(allmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
allmodel.coefficients<-allmodel.coefficients
colnames(allmodel.coefficients)<-allmodel.coefficients.name
print(allmodel.coefficients)
# Now do GARCH-in-mean models
gim.spec <- ugarchspec(variance.model=list(model="sGARCH", archm=TRUE, archpow=2),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE))
garch.in.mean.spx <- ugarchfit(data=alldata.xs$SPX.xs, spec=gim.spec)
x<-show(garch.in.mean.spx)
x@fit$coef
sum(x@fit$log.likelihoods)
x@fit$coef
x@fit$LLH
x@fit$residuals
x@fit$sigma
x@fit$cvar
x@fit$coef
x@fit$scores
x@fit$se.coef
x<-show(garch.in.mean.spx)
x@fit$matcoef
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$matcoef[,c(1,4)])
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$matcoef[,c(1,4)])
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
gim.spec <- ugarchspec(variance.model=list(model="sGARCH", archm=TRUE, archpow=2),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE))
garch.in.mean.spx <- ugarchfit(data=alldata.xs$SPX.xs, spec=gim.spec)
x<-show(garch.in.mean.spx)
x@fit$coef
x@fit$se.coef
sum(x@fit$log.likelihoods)
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$matcoef[,c(1,4)])
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
## Dale W.R. Rosenthal, 2018
## You are free to distribute and use this code so long as you attribute
## it to me or cite the text.
## The legal disclaimer in _A Quantitative Primer on Investments with R_
## applies to this code.  Use or distribution without these comment lines
## is forbidden.
library(xts)
library(quantmod)
library(Quandl)
library(rugarch)
Quandl.api_key('iVyBuKymy_j_R7Xxze9t')
# For industrial production, compute log-returns (% changes)
indprod <- Quandl("FRED/INDPRO", type="xts")
colnames(indprod) <- c("INDPROD")
indprod.logret <- diff(log(indprod))
exinfl <- Quandl("FRBC/EXIN", type="xts")[,1]
exinfl.diff <- diff(exinfl)
colnames(exinfl.diff) <- c("EXINFL.diff")
cpi <- Quandl("FRBC/USINFL", type="xts")[,1]
colnames(cpi) <- c("CPI")
excpi <- cpi*(1+exinfl)  # expected CPI in twelve months
cpi.surprise <- log(cpi) - log(lag(excpi, 12))  # % CPI surprise
colnames(cpi.surprise) <- c("INFLSURP")
t10y <- Quandl("FRED/DGS10", type="xts")/100
colnames(t10y) <- c("T10Y")
baa <- Quandl("FRED/INDPRO", type="xts")[,1]
colnames(baa) <- c("BAA")
baa.t10y<-baa-t10y
colnames(baa.t10y) <- c("BAA-T10Y")
t30y <- Quandl("FRED/DGS30", type="xts")/100
colnames(t30y) <- c("T30Y")
t3m <- Quandl("FRED/DGS3MO", type="xts")/100
colnames(t3m) <- c("T3M")
t30y.t3m<-t30y-t3m
colnames(t30y.t3m) <- c("T30Y-T3M")
chen <- cbind( t30y.t3m,indprod.logret, exinfl.diff, cpi.surprise, baa.t10y)
chen <- na.locf(chen)["20141001/20181001"]
# Get risk-free rate
rf.raw <- Quandl("FRED/DGS3MO", type="xts")/100
colnames(rf.raw) <- c("T3M")
# Get S&P 500, Russell 2000, and stock returns
adj.close <- 6  # 6th field is adjusted close
equity.tickers <- c("^GSPC","^RUT","BA","GD","HON","LMT","NOC","QCOM","RTN","UTX")
prices <- getSymbols(equity.tickers[1], source="yahoo", auto.assign=FALSE,
return.class="xts")[,adj.close]
for (i in 2:length(equity.tickers)) {
prices.tmp <- getSymbols(equity.tickers[i], source="yahoo",
auto.assign=FALSE, return.class="xts")[,adj.close]
prices <- cbind(prices, prices.tmp)
}
equity.names <- c("SPX","RUT","BA","GD","HON","LMT","NOC","QCOM","RTN","UTX")
colnames(prices) <- equity.names
returns <- diff(log(prices))
# Now we join all of the datasets together and trim to recent
alldata <- cbind(rf.raw, returns)["20141001/20181001"]
# create excess returns
equity.names.xs <- paste(equity.names, ".xs", sep="")
alldata.xs<-c()
# now in a for loop subtract off a daily risk-free rate, for example:
for (i in 1:length(equity.names)+1) {
xs.temp <- alldata[,i] - alldata$T3M/250
alldata.xs <- cbind(alldata.xs, xs.temp)
}
colnames(alldata.xs) <- equity.names.xs
alldata.xs<-na.omit(alldata.xs)["20141001/20181001"]
alldata.chen <- cbind( alldata.xs,chen)
alldata.chen <- na.locf(alldata.chen)["20141001/20181001"]
#model.temp <-lm(alldata.chen[,1]~alldata.chen[,12]+alldata.chen[,13]+alldata.chen[,14]+alldata.chen[,15]+alldata.chen[,11])
#model.temp<-summary(model.temp)
allmodel.coefficients<-c()
allmodel.coefficients.name<-c()
for (i in 1:length(equity.names)){
model.temp <-lm(alldata.chen[,i]~alldata.chen[,12]+alldata.chen[,13]+alldata.chen[,14]+alldata.chen[,15]+alldata.chen[,11])
model.temp<-summary(model.temp)
allmodel.coefficients<-cbind(allmodel.coefficients,model.temp$coefficients[,c(1,2,3,4)])
allmodel.coefficients.name<-cbind(allmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
allmodel.coefficients<-allmodel.coefficients
colnames(allmodel.coefficients)<-allmodel.coefficients.name
print(allmodel.coefficients)
# Now do GARCH-in-mean models
gim.spec <- ugarchspec(variance.model=list(model="sGARCH", archm=TRUE, archpow=2),
mean.model=list(armaOrder=c(0,0), include.mean=TRUE))
garch.in.mean.spx <- ugarchfit(data=alldata.xs$SPX.xs, spec=gim.spec)
x<-show(garch.in.mean.spx)
x@fit$coef
x@fit$se.coef
sum(x@fit$log.likelihoods)
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
#garch.coef<-cbind(garch.coef,x@fit$matcoef[,c(1,4)])
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$coef)
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$matcoef)
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
x@fit$matcoef[,2]
x@fit$matcoef[,c(1,3)]
x@fit$matcoef[,c(1,4)]
garch.coef<-c()
garch.MLE<-c()
for (i in 1:length(equity.names)){
x <- ugarchfit(data=alldata.xs[,i], spec=gim.spec)
garch.coef<-cbind(garch.coef,x@fit$matcoef[,c(1,4)])
garch.MLE<-cbind(garch.MLE,sum(x@fit$log.likelihoods))
}
colnames(garch.coef)<-equity.names
colnames(garch.MLE)<-equity.names
rownames(garch.MLE)<-"LLH"
garch.coef
garch.MLE
## Download Fama-French data
french.base <- "http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp"
factor.file <- "F-F_Research_Data_Factors_daily_CSV.zip"
french.url <- paste(french.base, factor.file, sep="/")
temp.file <- tempfile()
download.file(french.url, destfile=temp.file)
ff.tmp <- read.csv(unz(temp.file, "F-F_Research_Data_Factors_daily.CSV"),
header = TRUE, skip = 3)
unlink(temp.file)
# remove obnoxious last line, scale percentages, create xts object
ff.tmp <- ff.tmp[-length(ff.tmp[,1]),]
ff.data <- as.xts(ff.tmp[,c("SMB","HML")],
order.by=as.POSIXct(ff.tmp[[1]], format="%Y%m%d"))
ff.data <- ff.data["20141001/20181001"]
alldata.ff <- cbind( alldata.xs,ff.data)
alldata.ff <- na.locf(alldata.ff)["20141001/20181001"]
alldata.ff <- na.omit(alldata.ff)["20141001/20181001"]
ffmodel.coefficients<-c()
ffmodel.coefficients.name<-c()
for (i in 3:length(equity.names)){
model.temp <-lm(alldata.ff[,i]~alldata.ff[,1]+alldata.ff[,11]+alldata.ff[,12])
model.temp<-summary(model.temp)
ffmodel.coefficients<-cbind(ffmodel.coefficients,model.temp$coefficients[,c(1,4)])
ffmodel.coefficients.name<-cbind(ffmodel.coefficients.name,paste(colnames(alldata.xs)[i], ".Est", sep=""),paste(colnames(alldata.xs)[i], ".t", sep=""))
}
ffmodel.coefficients<-ffmodel.coefficients
colnames(ffmodel.coefficients)<-ffmodel.coefficients.name
print(ffmodel.coefficients)
View(ff.data)
## Dale W.R. Rosenthal, 2018
## You are free to distribute and use this code so long as you attribute
## it to me or cite the text.
## The legal disclaimer in _A Quantitative Primer on Investments with R_
## applies to this code.  Use or distribution without these comment lines
## is forbidden.
library(xts)
library(Quandl)
Quandl.api_key('iVyBuKymy_j_R7Xxze9t')
# Read in spot fx rates
fxspot.tickers <- c("CURRFX/USDEUR", "CURRFX/USDJPY", "CURRFX/USDCHF")
fxspot.raw <- Quandl(fxspot.tickers[1], type="xts")[,1]
for (i in 2:length(fxspot.tickers)) {
fxspot.temp <- Quandl(fxspot.tickers[i], type="xts")[,1]
fxspot.raw <- merge(fxspot.raw, fxspot.temp)
}
colnames(fxspot.raw) <- c("USDEUR.spot", "USDJPY.spot", "USDCHF.spot")
# Read in future fx rates
fxfut.tickers <- c("CHRIS/CME_EC1", "CHRIS/CME_JY1", "CHRIS/CME_SF1")
fxfut.raw <- Quandl(fxfut.tickers[2], type="xts")["20141001/20181001"]
fxfut.raw <- Quandl(fxfut.tickers[1], type="xts")[,6]
for (i in 2:length(fxfut.tickers)) {
fxfut.temp <- Quandl(fxfut.tickers[i], type="xts")[,6]
fxfut.raw <- merge(fxfut.raw, fxfut.temp)
}
colnames(fxfut.raw) <- c("USDEUR.fut", "USDJPY.fut", "USDCHF.fut")
fxfut.raw[,2]<-fxfut.raw[,2]/1000000
# Read in 3M USD deposit futures
usd.3m.raw <- Quandl("CHRIS/CME_ED1", type="xts")[,"Settle"]
eur.3m.raw <- Quandl("CHRIS/LIFFE_I1", type="xts")[,"Settle"]
jpy.3m.raw <- Quandl("CHRIS/CME_EY1", type="xts")[,"Settle"]
chf.3m.raw <- Quandl("CHRIS/LIFFE_S1", type="xts")[,"Settle"]
chf.3m.raw["20150122"] <- 101.08  # Fix 1st data error
chf.3m.raw["20150508"] <- 100.83  # Fix 2nd data error
deposits3m.raw <- cbind(usd.3m.raw, eur.3m.raw, jpy.3m.raw, chf.3m.raw)
deposits3m.raw <-deposits3m.raw
deposits3m <- (100-deposits3m.raw)/100  # convert futures prices to yield
colnames(deposits3m) <- c("3MUSDLIBOR", "3MCHFLIBOR", "3MJPYTIBOR", "3MEURIBOR")
alldata.full <- cbind(fxspot.raw, deposits3m, fxfut.raw)
alldata.full <- na.omit(alldata.full)
alldata <- alldata.full["20141001/20181001"]
g1<-alldata$USDJPY.spot*(1+alldata$X3MJPYTIBOR)
g2<-(1+alldata$X3MUSDLIBOR)/alldata$USDJPY.fut
gd<-g1-g2
plot(gd, xlab='t', ylab='JPY')
plot( g1, type='l', xlab='t', ylab='JPY')
points( g2, type='l',col="red")
mean(gd)
sd(gd)
library(moments)
skewness(gd,na.rm = T)
kurtosis(gd,na.rm = T)
library(MASS)
t<-c(1,5,15,20)
Yields<-c(0.49,0.3856,0.3537,0.2863)
B<-c(66.711,19.580,10.645,6.504)
risk<-c(0.0013,0.0011,0.0010,0.0009)
i=1
min.RSS <- function(par) {
((1-par[1])^Years[i]+(1-par[2])*(1-(1-par[1])^Years[i]))-(1+risk[i])/((1+Yields[i])^Years[i])}
result <- optim(par, fn = min.RSS,lower=c(0, 0), upper=c(1,1),method = "L-BFGS-B")
result$par
result$value
par<-c(0.1,0.9)
((par[1]^Years[i]+par[2]*(1-par[1]^Years[i])))*1000-Price[i]*(1+Yields[i])^Years[i]
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(1, 1), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(0, 1), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(0, 0), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(1, 0), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(1, 1), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(2, 2), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(5, 5), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(1, 1), fn = min.RSS,lower=c(-1, -1), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(0, 0), fn = min.RSS,lower=c(-1, -1), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
# Ch22
df = read.table(file="HW3_CH22.csv", header = TRUE,sep=",")
# par[1]is p, par[2]is L
min.RSS <- function(data, par) {
with(df, sum((((1000*(1-par[1])^T+1000*(1-par[2])*(1-(1-par[1])^T))/(1+Rf/100)^T)-B)^2))
}
result <- optim(par = c(1, 1), fn = min.RSS,lower=c(0, 0), upper=c(1, 1), data = df,method="L-BFGS-B")
result$par
result$value
