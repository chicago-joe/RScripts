supp<-c(supp,"tau")
date<-c(date,as.Date(i,"%Y.%d%m"))
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
error<-c(error,tau[num]-cpi[num])
num<-num+1
}
for (i in index(cpi)) {
print(index(cpi)[1])
date<-c(date,as.Date(index(cpi)[1],"%m月 %Y"))
v <- c(v,tau[num])
supp<-c(supp,"tau")
date<-c(date,as.Date(i,"%Y.%d%m"))
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
error<-c(error,tau[num]-cpi[num])
num<-num+1
}
date<-c(date,as.Date(index(cpi)[1],"%m月 %Y"))
date<-c(date,as.Date(index(cpi)[1],"%m %Y"))
date<-c(date,as.Date(index(cpi)[1],"%b %Y"))
date<-c(date,as.Date(index(cpi)[1],"%b%Y"))
date<-c(date,as.Date(index(cpi)[1],"%m/%Y"))
View(cpi)
cpi <- Quandl("FRBC/USINFL", type="xts")[,1]
colnames(cpi) <- c("CPI")
View(cpi)
View(cpi)
dates <- seq(as.Date("2017-05-01"),length=5,by="days")
dates <- seq(as.Date("2017-05-01"),length=5,by="months")
View(cpi)
dates <- seq(as.Date("1947-01-01"),length=860,by="months")
v <- c()
date <- c()
supp<-c()
error<-c()
num<-1
for (i in index(cpi)) {
#print(index(cpi)[1])
#date<-c(date,as.Date(index(cpi)[1],"%b%Y"))
v <- c(v,tau[num])
supp<-c(supp,"tau")
#date<-c(date,as.Date(i,"%Y.%d%m"))
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
error<-c(error,tau[num]-cpi[num])
num<-num+1
}
dates <- seq(as.Date("1947-01-01"),length=860,by="months")
date<-c(date,dates)
num<-1
for (i in index(cpi)) {
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
num<-num+1
}
date<-c(date,dates)
df <- data.frame(Value=v,
date=as.Date(date,"%Y"),type=supp)
# Change the color
p<-ggplot(df, aes(x=date, y=Value, color=type,group=type)) +
geom_line()
#p+ scale_color_gradientn(colours = rainbow(3))
p + scale_color_brewer(palette = "Set1")
View(df)
dates<-c(dates,dates)
df <- data.frame(Value=v,
date=as.Date(dates),type=supp)
# Change the color
p<-ggplot(df, aes(x=date, y=Value, color=type,group=type)) +
geom_line()
#p+ scale_color_gradientn(colours = rainbow(3))
p + scale_color_brewer(palette = "Set1")
df <- data.frame(Value=v,
date=as.Date(dates,"%Y-%m-%d"),type=supp)
v <- c()
date <- c()
supp<-c()
error<-c()
num<-1
for (i in index(cpi)) {
#print(index(cpi)[1])
#date<-c(date,as.Date(index(cpi)[1],"%b%Y"))
v <- c(v,tau[num])
supp<-c(supp,"tau")
#date<-c(date,as.Date(i,"%Y.%d%m"))
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
error<-c(error,tau[num]-cpi[num])
num<-num+1
}
dates <- seq(as.Date("1947-01-01"),length=860,by="months")
date<-c(date,dates)
num<-1
for (i in index(cpi)) {
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
num<-num+1
}
dates<-c(dates,dates)
v <- c()
date <- c()
supp<-c()
error<-c()
num<-1
for (i in index(cpi)) {
#print(index(cpi)[1])
#date<-c(date,as.Date(index(cpi)[1],"%b%Y"))
v <- c(v,tau[num])
supp<-c(supp,"tau")
#date<-c(date,as.Date(i,"%Y.%d%m"))
#v <- c(v,cpi[num])
#supp<-c(supp,"cpi")
error<-c(error,tau[num]-cpi[num])
num<-num+1
}
dates <- seq(as.Date("1947-01-01"),length=860,by="months")
date<-c(date,dates)
num<-1
for (i in index(cpi)) {
v <- c(v,cpi[num])
supp<-c(supp,"cpi")
num<-num+1
}
dates<-c(dates,dates)
df <- data.frame(Value=v,
date=as.Date(dates,"%Y-%m-%d"),type=supp)
# Change the color
p<-ggplot(df, aes(x=date, y=Value, color=type,group=type)) +
geom_line()
#p+ scale_color_gradientn(colours = rainbow(3))
p + scale_color_brewer(palette = "Set1")
install("keras")
install.packages("keras")
install.packages("lubridate")
install.packages("keras")
install.packages("magrittr")
install.packages("tidyr")
install.packages("dplyr")
install.packages("zoo")
install.packages("imputeTS")
install.packages("abind")
```{r}
library(keras)
library(lubridate)
library(magrittr)
library(tidyr)
library(dplyr)
library(zoo)
library(imputeTS)
library(abind)
```
## loading data
```{r}
dat <- read.csv("C:\Users\duany\Desktop\2017_M1_IEX.csv", head = F)
dat <- dat[,-3]
names(dat) <- c("tStamp", "ticker", "O", "H", "L", "C", "V")
dat$C <- as.numeric(dat$C)
dat$V <- as.numeric(dat$V)
```
## loading data
```{r}
dat <- read.csv("C:\\Users\\duany\\Desktop\\2017_M1_IEX.csv", head = F)
dat <- dat[,-3]
names(dat) <- c("tStamp", "ticker", "O", "H", "L", "C", "V")
dat$C <- as.numeric(dat$C)
dat$V <- as.numeric(dat$V)
```
```{r}
#features
pivot_C_dat <- dat %>% select(c(date, hour, minute, ticker, C)) %>% spread(key = ticker, value = C, fill = NA, convert = F)
colnames(pivot_C_dat) <- c(colnames(pivot_C_dat)[1:3], paste0(colnames(pivot_C_dat)[-(1:3)], "_C"))
pivot_V_dat <- dat %>% select(c(date, hour, minute, ticker, V)) %>% spread(key = ticker, value = V, fill = NA, convert = F)
colnames(pivot_V_dat) <- c(colnames(pivot_V_dat)[1:3],paste0(colnames(pivot_V_dat)[-(1:3)], "_V") )
pivot_dat <- pivot_C_dat %>% inner_join(pivot_V_dat)
print(colnames(pivot_dat))
```
## dealing with missing values with imputeTS
```{r}
for(col in colnames(pivot_dat)){
if(any(is.na(pivot_dat[,col]))){
pivot_dat[,col] = na.interpolation(pivot_dat[,col], "linear")
}
}
pivot_dat = pivot_dat %>% inner_join(final_dat) %>% select(-c(C, pre_price, post_price))
train_dat = pivot_dat %>% filter(date %in% train_date)
price_col = grepl("*_C", colnames(train_dat)) %>% which()
volume_col = grepl("*_V", colnames(train_dat)) %>% which()
valid_dat = pivot_dat %>% filter(date %in% valid_date)
test_dat = pivot_dat %>% filter(date %in% test_date)
me_price_train = sapply(1:length(price_col),FUN = function(i){mean(train_dat[,price_col[i]])})
sd_price_train = sapply(1:length(price_col),FUN = function(i){sd(train_dat[,price_col[i]]) })
me_volume_train = sapply(1:length(volume_col),FUN = function(i){mean(train_dat[,volume_col[i]])})
sd_volume_train = sapply(1:length(volume_col),FUN = function(i){sd(train_dat[,volume_col[i]])})
```
## rescaling the data set
```{r}
#training data
#price
for(i in 1:length(price_col) ){
col = price_col[i]
train_dat[,col] = scale(train_dat[,col], center = me_price_train[i], scale = sd_price_train[i])
}
#volume
for(i in 1:length(volume_col) ){
col = volume_col[i]
train_dat[,col] <- scale(train_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
```{r}
#features
pivot_C_dat <- dat %>% select(c(date, hour, minute, ticker, C)) %>% spread(key = ticker, value = C, fill = NA, convert = F)
colnames(pivot_C_dat) <- c(colnames(pivot_C_dat)[1:3], paste0(colnames(pivot_C_dat)[-(1:3)], "_C"))
pivot_V_dat <- dat %>% select(c(date, hour, minute, ticker, V)) %>% spread(key = ticker, value = V, fill = NA, convert = F)
colnames(pivot_V_dat) <- c(colnames(pivot_V_dat)[1:3],paste0(colnames(pivot_V_dat)[-(1:3)], "_V") )
pivot_dat <- pivot_C_dat %>% inner_join(pivot_V_dat)
print(colnames(pivot_dat))
```
##labeling
```{r}
for(each_date in all_date){
tmp = spy_dat %>% filter(date == each_date)
avgMprice = c(rep(0, w-1), zoo::rollmean(tmp$C, k=w, align = "left") )
tmp = tmp[-c((nrow(tmp)-w+1):nrow(tmp) ), ] # remove the last w ticks
tmp$pre_price = avgMprice[1:nrow(tmp)]
tmp$post_price = avgMprice[(w+1):(nrow(tmp)+w)]
move_ratio = tmp$pre_price - tmp$post_price
lab <- rep(1, nrow(tmp))
lab[move_ratio > r] = 0
lab[move_ratio < -r] = 2
lab[1:(w-1)] = -1
tmp$y <- lab
final_dat <- rbind(final_dat, tmp)
}
final_dat$y %>% table()
## prep data
```{r}
dat$C <- na.interpolation(dat$C, option = "linear")
dat$V <- na.replace(dat$V, 0)
dat$date <- as.factor(date(dat$tStamp))
dat$hour <- hour(dat$tStamp)
dat$minute <- minute(dat$tStamp)
# for cross validation
all_date <- dat$date %>% unique()
final_dat <- NULL
train_date <- all_date[1:150]
valid_date <- all_date[151:200]
test_date <- all_date[201:251]
w = 60
r = 0.08
TICKER <- c("AAPL", "MSFT", "AMZN", "BRK.B", "FB", "JNJ", "JPM", "XOM", "GOOG",
"GOOGL", "BAC", "PFE", "UNH", "V", "T", "WFC", "CVX", "VZ", "HD", "INTC", "SPY")
spy_dat <- dat %>% filter(ticker == "SPY") %>% select(date, hour, minute, C)
```
title: "hw-5-yang217"
author: "Yuting Yang"
date: "11/11/2018"
output: pdf_document
---
```{r}
library(keras)
library(lubridate)
library(magrittr)
library(tidyr)
library(dplyr)
library(zoo)
library(imputeTS)
library(abind)
```
---
```{r}
library(keras)
library(lubridate)
library(magrittr)
library(tidyr)
library(dplyr)
library(zoo)
library(imputeTS)
library(abind)
```
install.packages("imputeTS")
install.packages("abind")
install.packages("abind")
library(keras)
library(lubridate)
library(magrittr)
library(tidyr)
library(dplyr)
library(zoo)
library(imputeTS)
library(lubridate)
library(magrittr)
library(tidyr)
library(dplyr)
library(zoo)
library(abind)
library(imputeTS)
## loading data
```{r}
dat <- read.csv("C:\\Users\\duany\\Desktop\\2017_M1_IEX.csv", head = F)
dat <- dat[,-3]
names(dat) <- c("tStamp", "ticker", "O", "H", "L", "C", "V")
dat$C <- as.numeric(dat$C)
dat$V <- as.numeric(dat$V)
```
## prep data
```{r}
dat$C <- na.interpolation(dat$C, option = "linear")
dat$V <- na.replace(dat$V, 0)
dat$date <- as.factor(date(dat$tStamp))
dat$hour <- hour(dat$tStamp)
dat$minute <- minute(dat$tStamp)
# for cross validation
all_date <- dat$date %>% unique()
final_dat <- NULL
train_date <- all_date[1:150]
valid_date <- all_date[151:200]
test_date <- all_date[201:251]
w = 60
r = 0.08
TICKER <- c("AAPL", "MSFT", "AMZN", "BRK.B", "FB", "JNJ", "JPM", "XOM", "GOOG",
"GOOGL", "BAC", "PFE", "UNH", "V", "T", "WFC", "CVX", "VZ", "HD", "INTC", "SPY")
spy_dat <- dat %>% filter(ticker == "SPY") %>% select(date, hour, minute, C)
##labeling
```{r}
for(each_date in all_date){
tmp = spy_dat %>% filter(date == each_date)
avgMprice = c(rep(0, w-1), zoo::rollmean(tmp$C, k=w, align = "left") )
tmp = tmp[-c((nrow(tmp)-w+1):nrow(tmp) ), ] # remove the last w ticks
tmp$pre_price = avgMprice[1:nrow(tmp)]
tmp$post_price = avgMprice[(w+1):(nrow(tmp)+w)]
move_ratio = tmp$pre_price - tmp$post_price
lab <- rep(1, nrow(tmp))
lab[move_ratio > r] = 0
lab[move_ratio < -r] = 2
lab[1:(w-1)] = -1
tmp$y <- lab
final_dat <- rbind(final_dat, tmp)
}
final_dat$y %>% table()
```
```{r}
#features
pivot_C_dat <- dat %>% select(c(date, hour, minute, ticker, C)) %>% spread(key = ticker, value = C, fill = NA, convert = F)
colnames(pivot_C_dat) <- c(colnames(pivot_C_dat)[1:3], paste0(colnames(pivot_C_dat)[-(1:3)], "_C"))
pivot_V_dat <- dat %>% select(c(date, hour, minute, ticker, V)) %>% spread(key = ticker, value = V, fill = NA, convert = F)
colnames(pivot_V_dat) <- c(colnames(pivot_V_dat)[1:3],paste0(colnames(pivot_V_dat)[-(1:3)], "_V") )
pivot_dat <- pivot_C_dat %>% inner_join(pivot_V_dat)
print(colnames(pivot_dat))
```
## dealing with missing values with imputeTS
```{r}
for(col in colnames(pivot_dat)){
if(any(is.na(pivot_dat[,col]))){
pivot_dat[,col] = na.interpolation(pivot_dat[,col], "linear")
}
}
pivot_dat = pivot_dat %>% inner_join(final_dat) %>% select(-c(C, pre_price, post_price))
train_dat = pivot_dat %>% filter(date %in% train_date)
price_col = grepl("*_C", colnames(train_dat)) %>% which()
volume_col = grepl("*_V", colnames(train_dat)) %>% which()
valid_dat = pivot_dat %>% filter(date %in% valid_date)
test_dat = pivot_dat %>% filter(date %in% test_date)
me_price_train = sapply(1:length(price_col),FUN = function(i){mean(train_dat[,price_col[i]])})
sd_price_train = sapply(1:length(price_col),FUN = function(i){sd(train_dat[,price_col[i]]) })
me_volume_train = sapply(1:length(volume_col),FUN = function(i){mean(train_dat[,volume_col[i]])})
sd_volume_train = sapply(1:length(volume_col),FUN = function(i){sd(train_dat[,volume_col[i]])})
```
## rescaling the data set
```{r}
#training data
#price
for(i in 1:length(price_col) ){
col = price_col[i]
train_dat[,col] = scale(train_dat[,col], center = me_price_train[i], scale = sd_price_train[i])
}
#volume
for(i in 1:length(volume_col) ){
col = volume_col[i]
train_dat[,col] <- scale(train_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
for(i in 1:length(price_col) ){
col = price_col[i]
valid_dat[,col] = scale(valid_dat[,col],center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col = volume_col[i]
valid_dat[,col] = scale(valid_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
for(i in 1:length(price_col) ){
col = price_col[i]
valid_dat[,col] = scale(valid_dat[,col],center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col = volume_col[i]
valid_dat[,col] = scale(valid_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
for(i in 1:length(price_col) ){
col = price_col[i]
valid_dat[,col] = scale(valid_dat[,col],center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col = volume_col[i]
valid_dat[,col] = scale(valid_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
for(i in 1:length(price_col) ){
col = price_col[i]
valid_dat[,col] = scale(valid_dat[,col],center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col = volume_col[i]
valid_dat[,col] = scale(valid_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
for(i in 1:length(price_col) ){
col = price_col[i]
valid_dat[,col] = scale(valid_dat[,col],center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col = volume_col[i]
valid_dat[,col] = scale(valid_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
```{r}
# test data
for(i in 1:length(price_col) ){
col <- price_col[i]
test_dat[,col] <- scale(test_dat[,col], center = me_price_train[i], scale = sd_price_train[i])
}
for(i in 1:length(volume_col) ){
col <- volume_col[i]
test_dat[,col] <- scale(test_dat[,col], center = me_volume_train[i], scale = sd_volume_train[i])
}
## data generator
```{r}
sampling_generator <- function(data, batch_size, w)
{
function()
{
all_rows <- (data$y != -1) %>% which()
rows <- sample(all_rows, batch_size, replace = TRUE)
tmp <- Y <- X <- NULL
for(i in rows)
{
tmp <- rbind(tmp, as.matrix(data[(i-w+1):i,!(colnames(data) %in% c('y','date','hour','minute'))]))
Y <- c(Y, data$y[i])
}
X <- array_reshape(tmp, c(batch_size, w, dim(tmp)[2], 1), order = "F")
Y <- to_categorical(Y, num_classes = 3)
list(X, Y)
}
}
## building model
```{r}
model <- keras_model_sequential() %>%
layer_conv_2d(filters = 16, kernel_size = c(4,42), activation = 'relu', input_shape = c(w, 42, 1)) %>%
layer_conv_2d(filters = 32, kernel_size = c(1,1), activation = 'relu') %>%
layer_conv_2d(filters = 16, kernel_size = c(4, 1), activation = "relu") %>%
layer_flatten() %>%
layer_dense(units = 8, activation = "relu") %>%
layer_dense(units = 3, activation = "softmax")
model %>% compile(
loss = "categorical_crossentropy",
optimizer = optimizer_rmsprop(),
metrics = c("acc")
)
install.packages("keras")
install_github("rstudio/keras")
#install.packages("xts")
library(zoo)
library(xts)
library(Quandl)
library(ggplot2)
library(RColorBrewer)
library(Metrics)
Quandl.api_key('iVyBuKymy_j_R7Xxze9t')
####ex1
# Grab constant-maturity US Treasuries 3-Month Treasury Constant Maturity Rate; 2-Year Treasury Constant Maturity Rate; 10-Year Treasury Constant Maturity Rate; 30-Year Treasury Constant Maturity Rate E(R)
ust.tickers <- c("FRED/DGS3MO", "FRED/DGS2", "FRED/DGS5", "FRED/DGS10", "FRED/DGS30")
ust <- Quandl(ust.tickers, type="xts")/100
ust.colnames <- c("T3M", "T2Y", "T5Y", "T10Y", "T30Y")
colnames(ust) <- ust.colnames
View(ust)
# Grab inflation-indexed US Treasuries TIPS Yield Curve and Inflation Compensation E(r)
tips.yields <- c("TIPSY02", "TIPSY05", "TIPSY10")
tips <- Quandl("FED/TIPSY", type="xts")[,tips.yields]/100
View(tips)
View(tips)
View(ust)
## Dale W.R. Rosenthal, 2018
## You are free to distribute and use this code so long as you attribute
## it to me or cite the text.
## The legal disclaimer in _A Quantitative Primer on Investments with R_
## applies to this code.  Use or distribution without these comment lines
## is forbidden.
library(zoo)
library(Quandl)
library(xts)
library(quantmod)
library(PerformanceAnalytics)
Quandl.api_key("dU-ukkHjcYwUsDqmcvjB")
# Example of reading in CMTs from Quandl
# Name columns so we know what each holds after joining them together
ust.tickers <- c("FRED/DGS3MO", "FRED/DGS6MO", "FRED/DGS1", "FRED/DGS2", "FRED/DGS5", "FRED/DGS10", "FRED/DGS20", "FRED/DGS30")
ust.raw <- Quandl(ust.tickers, type="xts")["20141001/20181001"]/100
colnames(ust.raw) <- c("T3M.yld", "T6M.yld", "T1Y.yld", "T2Y.yld", "T5Y.yld", "T10Y.yld", "T20Y.yld", "T30Y.yld")
pca.usd <- prcomp(~ T3M.yld + T6M.yld + T1Y.yld + T2Y.yld + T5Y.yld + T10Y.yld + T20Y.yld + T30Y.yld,
data=ust.raw,
scale=FALSE, center=FALSE)
pca.usd <- prcomp(yc.usd, scale=FALSE, center=FALSE)
pca.usd$rotation  # eigenvectors
pca.usd$sdev^2    # eigenvalues
View(dat)
View(final_dat)
View(dat)
